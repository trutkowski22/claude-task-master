flowchart TB
    subgraph research-Imports["research-Imports"]
        I1["IMPORT: fs, FROM: fs"]
        I2["IMPORT: path, FROM: path"]
        I7["IMPORT: ContextGatherer, FROM: /claude-task-master/scripts/modules/utils/contextGatherer.js"]
        I8["IMPORT: FuzzyTaskSearch, FROM: /claude-task-master/scripts/modules/utils/fuzzyTaskSearch.js"]
        I9["IMPORT: generateTextService, FROM: /claude-task-master/scripts/modules/ai-services-unified.js"]
        I10["IMPORT: getPromptManager, FROM: /claude-task-master/scripts/modules/prompt-manager.js"]
        I11["IMPORT: log, FROM: /claude-task-master/scripts/modules/utils.js"]
        I12["IMPORT: findProjectRoot, FROM: /claude-task-master/scripts/modules/utils.js"]
        I13["IMPORT: readJSON, FROM: /claude-task-master/scripts/modules/utils.js"]
        I14["IMPORT: flattenTasksWithSubtasks, FROM: /claude-task-master/scripts/modules/utils.js"]
    end
    subgraph research-Dependencies["research-Dependencies"]
        D1["DEP: AI services (OpenAI, Anthropic, etc.)"]
        D2["DEP: File system"]
        D3["DEP: Terminal UI libraries"]
        D4["DEP: Syntax highlighting"]
        D5["DEP: Interactive prompts"]
    end
    subgraph research-FunctionsDefined["research-Functions Defined"]
        FU1["FUNCTION: performResearch"]
        FU2["FUNCTION: displayDetailedTokenBreakdown"]
        FU3["FUNCTION: processCodeBlocks"]
        FU4["FUNCTION: displayResearchResults"]
        FU5["FUNCTION: handleFollowUpQuestions"]
        FU6["FUNCTION: handleSaveToTask"]
        FU7["FUNCTION: handleSaveToFile"]
        FU8["FUNCTION: formatConversationForFile"]
        FU9["FUNCTION: formatConversationForSaving"]
        FU10["FUNCTION: buildConversationContext"]
    end
    subgraph research-Exports["research-Exports"]
        E1["EXP: performResearch"]
    end
    subgraph research-Parameters["research-Parameters"]
        P1["PARAM: {string} query - Research query/prompt"]
        P2["PARAM: {Object} options - Research options"]
        P3["PARAM: {Array<string>} options.taskIds - Task/subtask IDs for context"]
        P4["PARAM: {Array<string>} options.filePaths - File paths for context"]
        P5["PARAM: {string} options.customContext - Additional custom context"]
        P6["PARAM: {boolean} options.includeProjectTree - Include project file tree"]
        P7["PARAM: {string} options.detailLevel - Detail level: 'low', 'medium', 'high'"]
        P8["PARAM: {string} options.projectRoot - Project root directory"]
        P9["PARAM: {string} options.tag - Tag for the task"]
        P10["PARAM: {boolean} options.saveToFile - Whether to save results to file"]
        P11["PARAM: {Object} context - Execution context"]
        P12["PARAM: {Object} context.session - MCP session object"]
        P13["PARAM: {Object} context.mcpLog - MCP logger object"]
        P14["PARAM: {string} context.commandName - Command name for telemetry"]
        P15["PARAM: {string} context.outputType - Output type ('cli' or 'mcp')"]
        P16["PARAM: {string} outputFormat - Output format ('text' or 'json')"]
        P17["PARAM: {boolean} allowFollowUp - Whether to allow follow-up questions"]
    end
    subgraph research-Constants["research-Constants"]
        C1["CONST: isMCP, VALUE: !!mcpLog"]
        C2["CONST: projectRoot, VALUE: providedProjectRoot || findProjectRoot()"]
        C3["CONST: logFn, VALUE: logger function wrapper"]
        C4["CONST: contextGatherer, VALUE: new ContextGatherer()"]
        C5["CONST: finalTaskIds, VALUE: combined task IDs array"]
        C6["CONST: autoDiscoveredIds, VALUE: fuzzy search results"]
        C7["CONST: tasksData, VALUE: readJSON result"]
        C8["CONST: flattenedTasks, VALUE: flattenTasksWithSubtasks result"]
        C9["CONST: fuzzySearch, VALUE: new FuzzyTaskSearch()"]
        C10["CONST: contextResult, VALUE: contextGatherer.gather() result"]
        C11["CONST: gatheredContext, VALUE: contextResult.context"]
        C12["CONST: tokenBreakdown, VALUE: contextResult.tokenBreakdown"]
        C13["CONST: promptManager, VALUE: getPromptManager result"]
        C14["CONST: aiResult, VALUE: generateTextService result"]
        C15["CONST: researchResult, VALUE: aiResult.mainResult"]
        C16["CONST: telemetryData, VALUE: aiResult.telemetryData"]
        C17["CONST: conversationHistory, VALUE: conversation array"]
        C18["CONST: interactiveSaveInfo, VALUE: save tracking object"]
    end
    subgraph research-ExecutionFlow["research-Execution Flow"]
        FL1["Initialize project root and logging systems"]
        FL2["Auto-discover relevant tasks using fuzzy search"]
        FL3["Gather context from tasks, files, and project tree"]
        FL4["Load prompts using PromptManager with context"]
        FL5["Count tokens for context and prompts breakdown"]
        FL6["Display detailed token analysis in CLI mode"]
        FL7["Call AI service with research role and context"]
        FL8["Process and format AI response results"]
        FL9["Display research results with syntax highlighting"]
        FL10["Handle follow-up questions in interactive mode"]
        FL11["Process save-to-task or save-to-file requests"]
        FL12["Build conversation context for follow-ups"]
        FL13["Format and save conversation history"]
        FL14["Return research results with telemetry data"]
    end
    subgraph research["research.js"]
        research-Imports
        research-Dependencies
        research-FunctionsDefined
        research-Exports
        research-Parameters
        research-Constants
        research-ExecutionFlow
    end
    FL1 --> FL2
    FL2 --> FL3
    FL3 --> FL4
    FL4 --> FL5
    FL5 --> FL6
    FL6 --> FL7
    FL7 --> FL8
    FL8 --> FL9
    FL9 --> FL10
    FL10 --> FL11
    FL11 --> FL12
    FL12 --> FL13
    FL13 --> FL14